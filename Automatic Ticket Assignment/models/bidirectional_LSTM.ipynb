{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitcapstoneaimlmarchgroup2bnlppipenvfbe1d65e7d0d4715bbf9a458a8daab1e",
   "display_name": "Python 3.7.3 64-bit ('capstone_aimlmarchgroup2_b_nlp': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Requirement already satisfied: spacy_langdetect in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (0.1.2)\nRequirement already satisfied: pytest in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from spacy_langdetect) (5.3.5)\nRequirement already satisfied: langdetect==1.0.7 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from spacy_langdetect) (1.0.7)\nRequirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (1.5.0)\nRequirement already satisfied: packaging in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (20.1)\nRequirement already satisfied: wcwidth in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (0.1.8)\nRequirement already satisfied: more-itertools>=4.0.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (8.2.0)\nRequirement already satisfied: attrs>=17.4.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (19.3.0)\nRequirement already satisfied: pluggy<1.0,>=0.12 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (0.13.1)\nRequirement already satisfied: py>=1.5.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pytest->spacy_langdetect) (1.8.1)\nRequirement already satisfied: six in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from langdetect==1.0.7->spacy_langdetect) (1.14.0)\nRequirement already satisfied: zipp>=0.5 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest->spacy_langdetect) (2.2.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from packaging->pytest->spacy_langdetect) (2.4.6)\nRequirement already satisfied: contractions in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (0.0.24)\nRequirement already satisfied: textsearch in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from contractions) (0.0.17)\nRequirement already satisfied: pyahocorasick in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from textsearch->contractions) (1.4.0)\nRequirement already satisfied: Unidecode in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from textsearch->contractions) (1.1.1)\nRequirement already satisfied: pycountry in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (19.8.18)\nRequirement already satisfied: textblob in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (0.15.3)\nRequirement already satisfied: nltk>=3.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from textblob) (3.4.5)\nRequirement already satisfied: six in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\nRequirement already satisfied: openpyxl in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (3.0.3)\nRequirement already satisfied: jdcal in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from openpyxl) (1.4.1)\nRequirement already satisfied: et-xmlfile in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from openpyxl) (1.0.1)\nRequirement already satisfied: keras_preprocessing in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (1.1.0)\nRequirement already satisfied: numpy>=1.9.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras_preprocessing) (1.18.1)\nRequirement already satisfied: six>=1.9.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras_preprocessing) (1.14.0)\nRequirement already satisfied: keras in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (2.3.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (1.1.0)\nRequirement already satisfied: pyyaml in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (5.3)\nRequirement already satisfied: numpy>=1.9.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (1.18.1)\nRequirement already satisfied: h5py in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (2.10.0)\nRequirement already satisfied: six>=1.9.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (1.14.0)\nRequirement already satisfied: scipy>=0.14 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (1.4.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras) (1.0.8)\nRequirement already satisfied: tensorflow in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: astor>=0.6.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (0.8.1)\nRequirement already satisfied: gast==0.2.2 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (0.2.2)\nRequirement already satisfied: numpy<2.0,>=1.16.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.18.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (3.1.0)\nRequirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (0.34.2)\nRequirement already satisfied: wrapt>=1.11.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.11.2)\nRequirement already satisfied: six>=1.12.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.14.0)\nRequirement already satisfied: protobuf>=3.8.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (3.11.3)\nRequirement already satisfied: keras-applications>=1.0.8 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.0.8)\nRequirement already satisfied: termcolor>=1.1.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: absl-py>=0.7.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (0.9.0)\nRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.4.1)\nRequirement already satisfied: grpcio>=1.8.6 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.27.2)\nRequirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (2.1.0)\nRequirement already satisfied: keras-preprocessing>=1.1.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorflow) (0.1.8)\nRequirement already satisfied: setuptools in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow) (45.2.0)\nRequirement already satisfied: h5py in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow) (2.10.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (2.22.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (3.2.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (1.11.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.1)\nRequirement already satisfied: certifi>=2017.4.17 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.25.8)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.0.4)\nRequirement already satisfied: idna<2.9,>=2.5 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow) (2.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.2.8)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (4.0.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow) (3.1.0)\nRequirement already satisfied: sklearn in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (0.0)\nRequirement already satisfied: scikit-learn in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from sklearn) (0.22.2)\nRequirement already satisfied: scipy>=0.17.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.4.1)\nRequirement already satisfied: numpy>=1.11.0 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.18.1)\nRequirement already satisfied: joblib>=0.11 in /Users/vinay/.local/share/virtualenvs/capstone_aimlmarchgroup2_b_nlp-nyVBED4V/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.14.1)\n"
    }
   ],
   "source": [
    "# install additional dependencies \n",
    "!pip install spacy_langdetect\n",
    "!pip install contractions\n",
    "!pip install pycountry\n",
    "!pip install textblob\n",
    "!pip install openpyxl\n",
    "\n",
    "!pip install keras_preprocessing\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "[nltk_data] Downloading package stopwords to /Users/vinay/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas_profiling as pp\n",
    "\n",
    "#Importing libraries for text pre-processing\n",
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from contractions import contractions_dict\n",
    "import unicodedata\n",
    "from typing import Dict, List\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU, Dropout, Bidirectional, TimeDistributed\n",
    "from keras.layers import Activation, Concatenate, SpatialDropout1D, Input, Lambda, Flatten\n",
    "from keras.callbacks import EarlyStopping \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Reshape\n",
    "from keras.layers import Concatenate, concatenate\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "project_path: ../data/\n"
    }
   ],
   "source": [
    "env = \"local\" # colab\n",
    "project_path_local = \"../data/\"\n",
    "project_path_colab = \"/content/drive/My Drive/AIML 2019 GreatLearning/Capstone Project NLP/POC\"\n",
    "project_path = project_path_local if env == \"local\" else project_path_colab\n",
    "print(f\"project_path: {project_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_target_variables(row, count=3, original_target_col=\"Assignment group\", count_col=\"tmp_target_count\"):\n",
    "        if row[count_col] <= count:\n",
    "            return \"OTHER\"\n",
    "        else:\n",
    "            return row[original_target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_orig = pd.read_excel(f\"{project_path}/Input Data Synthetic CleanedV3.xlsx\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(5291, 14)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = df_en_orig[df_en_orig['lang_textblob']=='en']\n",
    "df_en.reset_index(inplace=True)\n",
    "df_en[\"tmp_target_count\"] = df_en.groupby([\"Assignment group\"])[\"Description\"].transform(\"count\") \n",
    "for index, row in df_en.iterrows():\n",
    "        df_en.loc[index, \"target1\"] = combine_target_variables(row)\n",
    "df_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "MAX_WORDS: 85\nSHORT_DESC_MAX_WORDS: 11\n"
    }
   ],
   "source": [
    "### Paramters\n",
    "df_en['description_cleaned_wc'] = df_en['description_cleaned'].apply(lambda x: len(str(x).split(\" \")))\n",
    "df_en['short_description_cleaned_wc'] = df_en['short_description_cleaned'].apply(lambda x: len(str(x).split(\" \")))\n",
    "MAX_WORDS = int(np.percentile(df_en['description_cleaned_wc'], 95))  ## based on 95 percentile\n",
    "SHORT_DESC_MAX_WORDS = int(np.percentile(df_en['short_description_cleaned_wc'], 95))  ## based on 95 percentile\n",
    "VALIDATION_SPLIT = 0.2 \n",
    "print(f\"MAX_WORDS: {MAX_WORDS}\")\n",
    "print(f\"SHORT_DESC_MAX_WORDS: {SHORT_DESC_MAX_WORDS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(df_en.description_cleaned)\n",
    "tokenizer.fit_on_texts(df_en.short_description_cleaned.apply(lambda x: f\"{x}\"))\n",
    "\n",
    "word_counts = tokenizer.word_counts\n",
    "word_docs = tokenizer.word_docs\n",
    "word_index = tokenizer.word_index\n",
    "index_word = tokenizer.index_word\n",
    "document_count = tokenizer.document_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "data.shape (5291, 85)\ndata[:2,:] [[ 406    6  119  142   90   73   52    6   73   18    5  189    6   33\n    52  295  163   53   33    9  116    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0]\n [  66  296  104  296    1  297   31  544 3476  189  261    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0]]\n"
    }
   ],
   "source": [
    "no_of_descriptions = df_en.description_cleaned.size\n",
    "data_shape = (no_of_descriptions, MAX_WORDS)\n",
    "data = np.zeros(data_shape, dtype=np.int64)\n",
    "print(\"data.shape\", data.shape)\n",
    "\n",
    "\n",
    "for description_i, description in enumerate(df_en.description_cleaned.to_list()):\n",
    "    # print(f\"{description_i+1} of {no_of_descriptions}\")\n",
    "    for word_i, word in enumerate(text_to_word_sequence(description)):\n",
    "        encoded_word = word_index[word]\n",
    "        if word_i >= MAX_WORDS:\n",
    "            break\n",
    "        elif word_i < MAX_WORDS:\n",
    "            # attempt to update data only if \n",
    "            # sentence_i < MAX_SENTS and word_i < MAX_SENT_LENGTH\n",
    "            data[description_i][word_i] = encoded_word\n",
    "\n",
    "print(\"data[:2,:]\", data[:2,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "short_data.shape (5291, 11)\nshort_data[:2,:] [[33  9  0  0  0  0  0  0  0  0  0]\n [31  0  0  0  0  0  0  0  0  0  0]]\nlogin issue\noutlook\n"
    }
   ],
   "source": [
    "no_of_short_descriptions = df_en.short_description_cleaned.size\n",
    "short_data_shape = (no_of_short_descriptions, SHORT_DESC_MAX_WORDS)\n",
    "short_data = np.zeros(short_data_shape, dtype=np.int64)\n",
    "print(\"short_data.shape\", short_data.shape)\n",
    "\n",
    "\n",
    "for description_i, description in enumerate(df_en.short_description_cleaned.apply(lambda x: f\"{x}\").to_list()):\n",
    "    # print(f\"{description_i+1} of {no_of_short_descriptions}\")\n",
    "    for word_i, word in enumerate(text_to_word_sequence(description)):\n",
    "        encoded_word = word_index[word]\n",
    "        if word_i >= SHORT_DESC_MAX_WORDS:\n",
    "            break\n",
    "        elif word_i < SHORT_DESC_MAX_WORDS:\n",
    "            # attempt to update short_data only if \n",
    "            # sentence_i < MAX_SENTS and word_i < MAX_SENT_LENGTH\n",
    "            short_data[description_i][word_i] = encoded_word\n",
    "\n",
    "print(\"short_data[:2,:]\", short_data[:2,:])\n",
    "print(index_word[33], index_word[9])\n",
    "print(index_word[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "TARGET_LEN: 55\n['GRP_0' 'GRP_1' 'GRP_3' 'GRP_4' 'GRP_5' 'GRP_8' 'GRP_6' 'GRP_10' 'GRP_9'\n 'GRP_11' 'GRP_14' 'GRP_15' 'GRP_17' 'GRP_18' 'GRP_2' 'GRP_19' 'GRP_20'\n 'GRP_21' 'GRP_25' 'GRP_13' 'GRP_16' 'GRP_26' 'GRP_27' 'GRP_28' 'GRP_29'\n 'GRP_30' 'GRP_31' 'GRP_22' 'GRP_24' 'GRP_7' 'GRP_12' 'GRP_34' 'OTHER'\n 'GRP_36' 'GRP_37' 'GRP_33' 'GRP_39' 'GRP_40' 'GRP_41' 'GRP_43' 'GRP_44'\n 'GRP_45' 'GRP_46' 'GRP_47' 'GRP_23' 'GRP_50' 'GRP_42' 'GRP_51' 'GRP_52'\n 'GRP_53' 'GRP_55' 'GRP_59' 'GRP_60' 'GRP_62' 'GRP_65']\n"
    }
   ],
   "source": [
    "# getting unique labels in given data\n",
    "labels = pd.get_dummies(df_en['target1']).values \n",
    "\n",
    "TARGET_LEN = len(df_en.target1.unique())\n",
    "print(f\"TARGET_LEN: {TARGET_LEN}\")\n",
    "print(df_en.target1.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "x_train.shape:  (4232, 85)   y_train.shape: (4232, 55)\nx_test.shape:  (1059, 85)   y_test.shape:  (1059, 55)\nx_train_short.shape:  (4232, 11)   y_train_short.shape: (4232, 55)\nx_test_short.shape:  (1059, 11)   y_test_short.shape:  (1059, 55)\n"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = VALIDATION_SPLIT, random_state=9) \n",
    "x_train_short, x_test_short, y_train_short, y_test_short = train_test_split(short_data, labels, test_size = VALIDATION_SPLIT, random_state=9) \n",
    "print(\"x_train.shape: \", x_train.shape, \"  y_train.shape:\", y_train.shape)\n",
    "print(\"x_test.shape: \", x_test.shape, \"  y_test.shape: \", y_test.shape) \n",
    "\n",
    "print(\"x_train_short.shape: \", x_train_short.shape, \"  y_train_short.shape:\", y_train_short.shape)\n",
    "print(\"x_test_short.shape: \", x_test_short.shape, \"  y_test_short.shape: \", y_test_short.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 85)           0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 11)           0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, 85, 150)      1440150     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, 11, 150)      1440150     input_2[0][0]                    \n__________________________________________________________________________________________________\nbidirectional_1 (Bidirectional) (None, 300)          361200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nbidirectional_2 (Bidirectional) (None, 300)          361200      embedding_2[0][0]                \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 600)          0           bidirectional_1[0][0]            \n                                                                 bidirectional_2[0][0]            \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 256)          153856      concatenate_1[0][0]              \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 55)           14135       dropout_1[0][0]                  \n==================================================================================================\nTotal params: 3,770,691\nTrainable params: 3,770,691\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "### trying with regularizing embedding\n",
    "\n",
    "LSTM_DIM = MAX_WORDS # 128\n",
    "OUTPUT_LEN = 150 # embedding_dimentations\n",
    "vocab_size = len(tokenizer.word_index.keys()) + 1\n",
    "\n",
    "description_encoder_inputs = Input(shape=(MAX_WORDS,))\n",
    "\n",
    "# x1 = Reshape((400,))(description_encoder_inputs)\n",
    "x2 = Embedding(\n",
    "        output_dim=OUTPUT_LEN, \n",
    "        input_dim=vocab_size, \n",
    "        input_length=MAX_WORDS, \n",
    "        embeddings_regularizer=keras.regularizers.l2(.001))(description_encoder_inputs)\n",
    "\n",
    "description_encoder = Bidirectional(LSTM(OUTPUT_LEN, dropout=0.25, recurrent_dropout=0.25)) # return_state=True\n",
    "description_encoder_outputs = description_encoder(x2) # description_state_h, description_state_c\n",
    "\n",
    "\n",
    "short_description_encoder_inputs = Input(shape=(SHORT_DESC_MAX_WORDS,))\n",
    "\n",
    "# sx1 = Reshape((400,))(short_description_encoder_inputs)\n",
    "sx2 = Embedding(\n",
    "        output_dim=OUTPUT_LEN, \n",
    "        input_dim=vocab_size, \n",
    "        input_length=SHORT_DESC_MAX_WORDS, \n",
    "        embeddings_regularizer=keras.regularizers.l2(.001))(short_description_encoder_inputs)\n",
    "\n",
    "short_description_encoder = Bidirectional(LSTM(OUTPUT_LEN, dropout=0.25, recurrent_dropout=0.25)) # return_state=True\n",
    "short_description_encoder_outputs = short_description_encoder(sx2) # description_state_h, description_state_c\n",
    "\n",
    "combined_context_vector = concatenate([description_encoder_outputs, short_description_encoder_outputs])\n",
    "\n",
    "d1 = Dense(units = 256, activation='relu')(combined_context_vector) # combined_context_vector\n",
    "d2 = Dropout(0.2)(d1)\n",
    "predictions = Dense(TARGET_LEN, activation='softmax')(d2) \n",
    "\n",
    "bidirectional_lstm_model = Model(inputs=[description_encoder_inputs, short_description_encoder_inputs], outputs=predictions)\n",
    "bidirectional_lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(bidirectional_lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Training...\nTrain on 3385 samples, validate on 847 samples\nEpoch 1/10\n3385/3385 [==============================] - 60s 18ms/step - loss: 1.8652 - accuracy: 0.5666 - val_loss: 1.9937 - val_accuracy: 0.5443\n\nEpoch 00001: saving model to saved_models/bidirectional-lstm-01-0.54.hdf5\nEpoch 2/10\n3385/3385 [==============================] - 57s 17ms/step - loss: 1.6841 - accuracy: 0.6035 - val_loss: 1.9880 - val_accuracy: 0.5632\n\nEpoch 00002: saving model to saved_models/bidirectional-lstm-02-0.56.hdf5\nEpoch 3/10\n3385/3385 [==============================] - 52s 15ms/step - loss: 1.5380 - accuracy: 0.6281 - val_loss: 1.9920 - val_accuracy: 0.5596\n\nEpoch 00003: saving model to saved_models/bidirectional-lstm-03-0.56.hdf5\nEpoch 4/10\n3385/3385 [==============================] - 56s 17ms/step - loss: 1.4550 - accuracy: 0.6496 - val_loss: 2.0379 - val_accuracy: 0.5714\n\nEpoch 00004: saving model to saved_models/bidirectional-lstm-04-0.57.hdf5\nEpoch 5/10\n3385/3385 [==============================] - 56s 16ms/step - loss: 1.3337 - accuracy: 0.6877 - val_loss: 2.0725 - val_accuracy: 0.5762\n\nEpoch 00005: saving model to saved_models/bidirectional-lstm-05-0.58.hdf5\nEpoch 6/10\n3385/3385 [==============================] - 58s 17ms/step - loss: 1.2174 - accuracy: 0.7208 - val_loss: 2.1515 - val_accuracy: 0.5608\n\nEpoch 00006: saving model to saved_models/bidirectional-lstm-06-0.56.hdf5\nEpoch 7/10\n3385/3385 [==============================] - 63s 19ms/step - loss: 1.1225 - accuracy: 0.7409 - val_loss: 2.2951 - val_accuracy: 0.5844\n\nEpoch 00007: saving model to saved_models/bidirectional-lstm-07-0.58.hdf5\nEpoch 8/10\n3385/3385 [==============================] - 60s 18ms/step - loss: 1.0209 - accuracy: 0.7770 - val_loss: 2.2949 - val_accuracy: 0.5679\n\nEpoch 00008: saving model to saved_models/bidirectional-lstm-08-0.57.hdf5\nEpoch 9/10\n3385/3385 [==============================] - 60s 18ms/step - loss: 0.9516 - accuracy: 0.7962 - val_loss: 2.5142 - val_accuracy: 0.5561\n\nEpoch 00009: saving model to saved_models/bidirectional-lstm-09-0.56.hdf5\nEpoch 10/10\n3385/3385 [==============================] - 63s 18ms/step - loss: 0.8793 - accuracy: 0.8142 - val_loss: 2.4981 - val_accuracy: 0.5714\n\nEpoch 00010: saving model to saved_models/bidirectional-lstm-10-0.57.hdf5\nCPU times: user 19min 12s, sys: 4min 45s, total: 23min 57s\nWall time: 9min 52s\n"
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.callbacks.History at 0x137e969e8>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# batch_size = 32\n",
    "# model.fit(x_train_re, y_train, epochs=5, batch_size=batch_size, verbose=2, validation_split=VALIDATION_SPLIT)\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "# filepath = \"saved-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "# filepath = \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "filepath = \"saved_models/bidirectional-lstm-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='auto')\n",
    "\n",
    "print('Training...')\n",
    "\n",
    "bidirectional_lstm_model.fit([x_train, x_train_short], y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=VALIDATION_SPLIT,\n",
    "          callbacks=[checkpoint]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1059/1059 [==============================] - 4s 4ms/step\nTest loss: 2.415554674421424\nTest accuracy: 0.585457980632782\nCPU times: user 9.15 s, sys: 1.12 s, total: 10.3 s\nWall time: 4.43 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# evaluating model on validation data set\n",
    " \n",
    "loss, acc = bidirectional_lstm_model.evaluate([x_test, x_test_short], y_test, batch_size=batch_size)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "1059/1059 [==============================] - 6s 5ms/step\ny_pred_class: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
    }
   ],
   "source": [
    "y_pred = bidirectional_lstm_model.predict([x_test, x_test_short], verbose=1)\n",
    "y_pred_index = np.argmax(y_pred, axis=1)\n",
    "y_pred_class = (y_pred == y_pred.max(axis=1, keepdims=True)).astype(int)\n",
    "print(f\"y_pred_class: {y_pred_class[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "y_pred_class:  [[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\ny_test:  [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n              precision    recall  f1-score   support\n\n       GRP_0       0.75      0.87      0.80       511\n       GRP_1       0.00      0.00      0.00         6\n       GRP_3       0.06      0.10      0.07        10\n       GRP_4       0.00      0.00      0.00         5\n       GRP_5       0.57      0.41      0.48        29\n       GRP_8       0.55      0.43      0.48        28\n       GRP_6       0.38      0.47      0.42        17\n      GRP_10       0.00      0.00      0.00         5\n       GRP_9       0.40      0.21      0.28        19\n      GRP_11       0.00      0.00      0.00         4\n      GRP_14       0.22      0.14      0.17        14\n      GRP_15       0.18      0.17      0.17        36\n      GRP_17       0.44      0.38      0.41        40\n      GRP_18       0.00      0.00      0.00         7\n       GRP_2       0.40      0.29      0.33         7\n      GRP_19       0.00      0.00      0.00         6\n      GRP_20       0.00      0.00      0.00         5\n      GRP_21       0.40      0.50      0.44         4\n      GRP_25       0.12      0.17      0.14        12\n      GRP_13       0.25      0.10      0.14        10\n      GRP_16       0.00      0.00      0.00         1\n      GRP_26       0.00      0.00      0.00         9\n      GRP_27       0.21      0.33      0.26        15\n      GRP_28       0.22      0.21      0.22        28\n      GRP_29       0.50      0.50      0.50         2\n      GRP_30       0.00      0.00      0.00         4\n      GRP_31       0.00      0.00      0.00         7\n      GRP_22       0.00      0.00      0.00        12\n      GRP_24       0.00      0.00      0.00         4\n       GRP_7       0.00      0.00      0.00         1\n      GRP_12       0.00      0.00      0.00         1\n      GRP_34       0.20      0.11      0.14        18\n       OTHER       0.10      0.29      0.15         7\n      GRP_36       0.25      0.43      0.32         7\n      GRP_37       0.00      0.00      0.00         1\n      GRP_33       0.00      0.00      0.00         0\n      GRP_39       0.00      0.00      0.00         3\n      GRP_40       0.00      0.00      0.00         4\n      GRP_41       0.00      0.00      0.00         1\n      GRP_43       0.00      0.00      0.00         2\n      GRP_44       0.58      0.78      0.67        18\n      GRP_45       0.00      0.00      0.00         4\n      GRP_46       0.00      0.00      0.00         1\n      GRP_47       0.00      0.00      0.00         2\n      GRP_23       0.00      0.00      0.00         3\n      GRP_50       0.00      0.00      0.00         2\n      GRP_42       0.00      0.00      0.00         1\n      GRP_51       0.78      0.50      0.61        14\n      GRP_52       0.00      0.00      0.00         1\n      GRP_53       0.00      0.00      0.00         8\n      GRP_55       0.00      0.00      0.00         0\n      GRP_59       0.21      0.33      0.26         9\n      GRP_60       0.83      0.74      0.78        81\n      GRP_62       0.32      0.50      0.39        12\n      GRP_65       0.00      0.00      0.00         1\n\n   micro avg       0.59      0.59      0.59      1059\n   macro avg       0.16      0.16      0.16      1059\nweighted avg       0.54      0.59      0.56      1059\n samples avg       0.59      0.59      0.59      1059\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"y_pred_class: \", y_pred_class[:1])\n",
    "print(\"y_test: \", y_test[:1])\n",
    "print(classification_report(y_test, y_pred_class, target_names=df_en.target1.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}