{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iChac8lqi8tS"
   },
   "source": [
    "Encoder with Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i1BvVjR4ix-5"
   },
   "source": [
    "- Encoder: The encoder is responsible for stepping through the input time steps and encoding the entire sequence into a fixed length vector called a context vector.\n",
    "- Decoder: The decoder is responsible for stepping through the output time steps while reading from the context vector.\n",
    "\n",
    "Attention is an extension to the architecture that addresses the poor performance. It works by first providing a richer context from the encoder to the decoder and a learning mechanism where the decoder can learn where to pay attention in the richer encoding when predicting each time step in the output sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PG1-fRX2iuID"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ru0dhb6Oiucn"
   },
   "outputs": [],
   "source": [
    "# dfcl for data frame with cleaned text\n",
    "dfcl = pd.read_excel(\"/content/drive/My Drive/Colab Notebooks/NLP/Capstone Project/AUTOMATIC TICKET ASSIGNMENT/Input Data Synthetic CleanedV2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "hdnc56QuiufG",
    "outputId": "006dad9e-7548-49f9-93e9-30e88aeae0aa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Short description</th>\n",
       "      <th>Description</th>\n",
       "      <th>Caller</th>\n",
       "      <th>Assignment group</th>\n",
       "      <th>description_cleaned</th>\n",
       "      <th>short_description_cleaned</th>\n",
       "      <th>tmp_target_count</th>\n",
       "      <th>target1</th>\n",
       "      <th>spacy_col</th>\n",
       "      <th>language</th>\n",
       "      <th>score</th>\n",
       "      <th>lang_textblob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>login issue</td>\n",
       "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
       "      <td>spxjnwir pjlcoqds</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>verify user detail employee manager name check...</td>\n",
       "      <td>login issue</td>\n",
       "      <td>3975</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>verify user detail employee manager name check...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>outlook</td>\n",
       "      <td>\\n\\nreceived from: hmjdrvpb.komuaywn@gmail.com...</td>\n",
       "      <td>hmjdrvpb komuaywn</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>team meeting skype meeting not appear outlook ...</td>\n",
       "      <td>outlook</td>\n",
       "      <td>3975</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>team meeting skype meeting not appear outlook ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cant log in to vpn</td>\n",
       "      <td>\\n\\nreceived from: eylqgodm.ybqkwiam@gmail.com...</td>\n",
       "      <td>eylqgodm ybqkwiam</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>can not log vpn</td>\n",
       "      <td>can not log vpn</td>\n",
       "      <td>3975</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>can not log vpn</td>\n",
       "      <td>en</td>\n",
       "      <td>0.571427</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>unable to access hr_tool page</td>\n",
       "      <td>unable to access hr_tool page</td>\n",
       "      <td>xbkucsvz gcpydteq</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>3975</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>unable access hr tool page</td>\n",
       "      <td>fr</td>\n",
       "      <td>0.428573</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error</td>\n",
       "      <td>owlgqjme qhcozdfx</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>skype error</td>\n",
       "      <td>skype error</td>\n",
       "      <td>3975</td>\n",
       "      <td>GRP_0</td>\n",
       "      <td>skype error</td>\n",
       "      <td>no</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0              Short description  ...     score lang_textblob\n",
       "0           0                    login issue  ...  0.999996            en\n",
       "1           1                        outlook  ...  0.999994            en\n",
       "2           2             cant log in to vpn  ...  0.571427            en\n",
       "3           3  unable to access hr_tool page  ...  0.428573            en\n",
       "4           4                   skype error   ...  0.999994            no\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "uyv6rM43uXGG",
    "outputId": "500287ce-1649-45fb-cf81-a5b02ca5cc98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en       5294\n",
       "sl        537\n",
       "fr        487\n",
       "af        418\n",
       "de        412\n",
       "it        174\n",
       "sv        153\n",
       "da        144\n",
       "no        132\n",
       "nl        131\n",
       "ca        129\n",
       "ro         75\n",
       "error      73\n",
       "es         70\n",
       "pt         64\n",
       "Name: lang_textblob, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfcl['lang_textblob'].value_counts()[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YF_Lipidiulc",
    "outputId": "91149896-a1fd-4d91-c748-ec776e5910f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5294, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## data only contains english language\n",
    "dfen = dfcl[dfcl['lang_textblob']=='en']\n",
    "dfen.reset_index(inplace=True)\n",
    "\n",
    "dfen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXbOPVxxiuhf"
   },
   "outputs": [],
   "source": [
    "### Paramters\n",
    "max_words = 55 ### based on 90 percentile\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "-9fRYp3FiuoK",
    "outputId": "6830f439-bd87-412f-cf9d-8098d0c16c22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Import few required libraries\n",
    "import nltk\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "1SC03V2bvegd",
    "outputId": "ce09a98a-402a-469b-95ff-679bc8ae7611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WhqcFbuL2_1H"
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer(num_words=max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cGK3839-2_36"
   },
   "outputs": [],
   "source": [
    "tk.fit_on_texts(dfen['description_cleaned'])\n",
    "# tk.fit_on_texts(dfen['short_description_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WJ8d_6ABBwbu",
    "outputId": "1e3c639d-045c-402a-c4d4-9a23f0977464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words : 9005\n",
      "('horrible', 1)\n"
     ]
    }
   ],
   "source": [
    "word_counts = tk.word_counts\n",
    "print('number of unique words : ' + str(len(word_counts)))\n",
    "\n",
    "# checking some random entries in the word_counts dictionary\n",
    "print(random.choice(list(word_counts.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apyWBG_ji-gr"
   },
   "outputs": [],
   "source": [
    "max_len = len(tk.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXgYY6-Z2__J"
   },
   "outputs": [],
   "source": [
    "words_list = []   ## list to be used to store the words after word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cSpbIumF7i-I"
   },
   "outputs": [],
   "source": [
    "# converting text to sequence of numbers\n",
    "seq = tk.texts_to_sequences(dfen['description_cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "dwf5AXSBG-36",
    "outputId": "49b1b56d-3458-49fb-d511-a58c9e9a70b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 45, 5, 26, 7, 5, 39, 45, 39, 10]\n",
      "[3]\n",
      "[3]\n",
      "[51, 16, 8]\n",
      "[28, 13]\n",
      "[11, 1, 5]\n",
      "[8, 3, 51]\n",
      "[8, 15, 3]\n",
      "[51, 39, 8]\n",
      "[51, 39, 12, 42, 33, 3, 29, 25, 24]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "for i, sq in enumerate(seq):\n",
    "  print(sq)\n",
    "  if i == 10:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p098DO4Uw_fZ",
    "outputId": "7ed72564-277a-42b5-dd2a-3acd402a340e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dac gso a basis oncall detail modify modify place location collaboration platform update record accordingly'"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfen['description_cleaned'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z-bmndJ_xSPs",
    "outputId": "d7288825-6d1b-450a-cf2e-c85e3430f664"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hr tool site not load page correctly']"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(dfen['description_cleaned'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9jZ1Xov1wwEp",
    "outputId": "ddb7d4d5-0fb9-4b9a-923e-f4504a49ac91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verify user detail employee manager name check user name reset password advise user login check caller confirm able login issue resolve']"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = []\n",
    "for i in range(len(dfen)):\n",
    "  articles.append(sent_tokenize(dfen['description_cleaned'][i]))\n",
    "\n",
    "articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGkggPSaHrUN"
   },
   "outputs": [],
   "source": [
    "### initializing the placeholder variable\n",
    "MAX_SENTS = 1\n",
    "data = np.zeros((len(dfen['short_description_cleaned']), MAX_SENTS, max_words), dtype='int32')\n",
    "\n",
    "### word index encoding\n",
    "for i, sentence in enumerate(articles):\n",
    "    for j, sent in enumerate(sentence):\n",
    "        if j < MAX_SENTS:\n",
    "            wordTokens = text_to_word_sequence(sent)\n",
    "            k = 0\n",
    "            for _, word in enumerate(wordTokens):\n",
    "                try:\n",
    "                    if k < max_words and tk.word_index[word] < max_len:\n",
    "                      data[i, j, k] = tk.word_index[word]\n",
    "                      k = k + 1\n",
    "                except:\n",
    "                      #  print(word)\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "E9ltSyxPbW8z",
    "outputId": "bfc2bc80-3c9b-4cb5-ac2a-c9ed59460c73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4689"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index['idbdaily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pznBOW-WPdWI",
    "outputId": "8d10cbb3-20b0-4101-c48c-c9f95fc746b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'network'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordTokens[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ahvCVGpOk5gT",
    "outputId": "06caa52e-9f82-4114-a40b-8e45198de146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5294, 1, 55)"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "YD8u3JfAk9qn",
    "outputId": "3b7518e9-5418-421c-fe9b-1d4dec50affd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unable',\n",
       " 'access',\n",
       " 'machine',\n",
       " 'utility',\n",
       " 'finish',\n",
       " 'drawer',\n",
       " 'adjustment',\n",
       " 'setting',\n",
       " 'no',\n",
       " 'network']"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rpEMiNv5EYP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kis5ZWURqlZ3",
    "outputId": "b5e44195-008e-447a-a17b-85483d54d360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.word_index['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "lPJHMwXCkZSh",
    "outputId": "e064446f-ddad-46a1-e975-dc96a30856e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 201,  214,   26,    7, 1922,  255,  199,  147,  342,  709,   25,\n",
       "        1154,   59, 1280,  172,  252,   53,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[34,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Id1nbEYP2nZ"
   },
   "outputs": [],
   "source": [
    "# converting labels into one-hot vectors\n",
    "labels = pd.get_dummies(dfen['target1']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "IAgralCRRCwG",
    "outputId": "ca18aba9-e378-4c4c-eb6b-f70ac32e697f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5294, 1, 55)\n",
      "(5294, 59)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3HdMSAlRJyJ"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size = validation_split, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Jsz9EovudKw1",
    "outputId": "638d3187-ca69-4f65-e30f-82786aec95db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4235, 1, 55) (4235, 59)\n",
      "(1059, 1, 55) (1059, 59)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZTtd4nMTdQ3H"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, Bidirectional, TimeDistributed\n",
    "from keras.layers import Activation, Concatenate, SpatialDropout1D, Input, Lambda, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8GFL5IbPnCS"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import Model\n",
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lOOAN3zjOjwA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fgeCBPjqr71"
   },
   "source": [
    "Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ljwDw-TLrG-7"
   },
   "outputs": [],
   "source": [
    "### Reshaping data for the input to LSTM model\n",
    "\n",
    "x_train_re = np.reshape(x_train, (len(x_train), 55))\n",
    "x_test_re = np.reshape(x_test, (len(x_test), 55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "nraTA6UKeOmR",
    "outputId": "9fa6fb08-932e-4508-e33e-81c3dee72237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 55, 150)           1350750   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 55, 150)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               285696    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 59)                15163     \n",
      "=================================================================\n",
      "Total params: 1,684,633\n",
      "Trainable params: 1,684,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "### trying with regularizing embedding\n",
    "\n",
    "lstm_dim = 128\n",
    "output_length = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(output_dim = output_length, input_dim = max_len, input_length = 55, \n",
    "                    embeddings_regularizer=keras.regularizers.l2(.001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(lstm_dim), merge_mode = 'sum'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units = 59, activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "alMaaYnofNMT",
    "outputId": "353ddfdc-c8ce-4c22-eabf-2b13bb208ebe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 3388 samples, validate on 847 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 25s - loss: 2.7760 - acc: 0.4684 - val_loss: 2.1475 - val_acc: 0.5325\n",
      "Epoch 2/10\n",
      " - 22s - loss: 2.1040 - acc: 0.5345 - val_loss: 2.0252 - val_acc: 0.5620\n",
      "Epoch 3/10\n",
      " - 22s - loss: 1.9456 - acc: 0.5587 - val_loss: 1.9750 - val_acc: 0.5714\n",
      "Epoch 4/10\n",
      " - 22s - loss: 1.7936 - acc: 0.5885 - val_loss: 1.9342 - val_acc: 0.5998\n",
      "Epoch 5/10\n",
      " - 22s - loss: 1.6827 - acc: 0.6110 - val_loss: 1.9726 - val_acc: 0.6009\n",
      "Epoch 6/10\n",
      " - 22s - loss: 1.5380 - acc: 0.6417 - val_loss: 2.1422 - val_acc: 0.5785\n",
      "Epoch 7/10\n",
      " - 22s - loss: 1.4368 - acc: 0.6588 - val_loss: 2.1143 - val_acc: 0.5714\n",
      "Epoch 8/10\n",
      " - 22s - loss: 1.3252 - acc: 0.6948 - val_loss: 2.0885 - val_acc: 0.5762\n",
      "Epoch 9/10\n",
      " - 22s - loss: 1.2182 - acc: 0.7329 - val_loss: 2.1226 - val_acc: 0.5986\n",
      "Epoch 10/10\n",
      " - 22s - loss: 1.1378 - acc: 0.7479 - val_loss: 2.2295 - val_acc: 0.5856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c29917ac8>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model.fit(x_train_re, y_train, epochs = 10, batch_size=batch_size, verbose = 2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zkPoLwUAtW07",
    "outputId": "d1719194-abda-43c2-9bda-39c85a45e836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 2.26\n",
      "acc: 0.58\n"
     ]
    }
   ],
   "source": [
    "score,acc = model.evaluate(x_test_re, y_test, verbose = 2, batch_size = batch_size)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TG7mhAX8uPNR"
   },
   "source": [
    "ELMO Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LsbFIBFXDgM"
   },
   "outputs": [],
   "source": [
    "### Try ELMO embedding\n",
    "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/1\", trainable=True)\n",
    "\n",
    "def ElmoEmbedding(x):\n",
    "    return elmo_model(inputs={\n",
    "                            \"tokens\": tf.squeeze(tf.cast(x, tf.string)),\n",
    "                            \"sequence_len\": tf.constant(batch_size*[max_len])\n",
    "                      },\n",
    "                      signature=\"tokens\",\n",
    "                      as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "tc0T_O01XDdy",
    "outputId": "4ee63393-f1cf-439e-f590-0470cf692d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 9005, 55)          0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 9005, 1024)        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 9005, 256)         1180672   \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9005, 59)          15163     \n",
      "=================================================================\n",
      "Total params: 1,195,835\n",
      "Trainable params: 1,195,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "input_text = Input(shape=(max_len, 55), dtype=tf.string)\n",
    "embedding = Lambda(ElmoEmbedding, output_shape=(max_len, 1024))(input_text)\n",
    "x3 = Bidirectional(LSTM(lstm_dim, return_sequences=True, dropout=0.2))(embedding)\n",
    "out = TimeDistributed(Dense(59, activation='softmax'))(x3)\n",
    "\n",
    "model_el = Model(input_text, out)\n",
    "\n",
    "model_el.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VV6vgFr1fOR6"
   },
   "outputs": [],
   "source": [
    "### Try with Glove Embedding\n",
    "\"\"\"\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./glove.6B.100d.txt')\n",
    "for line in f:\n",
    "\tvalues = line.split()\n",
    "\tword = values[0]\n",
    "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\tembeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "\n",
    "\n",
    "for word, i in tk.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iV2vk_pQtvK7"
   },
   "source": [
    "Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oi4QC3MxMFvH"
   },
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        ### Inside build (), weights and biases are defined\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        ### Inside call (), main logic of Attention will be written\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        ### get_config() method collects the input shape and other information about the model\n",
    "        return super(attention,self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "IcqBAVsNMFry",
    "outputId": "e12a4135-b93c-4bf2-c2dc-d732387f7876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 55, 150)           1350900   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 59)                5959      \n",
      "=================================================================\n",
      "Total params: 1,457,259\n",
      "Trainable params: 1,457,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### With attention layer\n",
    "inputs2=Input(shape=(55,))\n",
    "x1=Embedding(input_dim=len(tk.word_counts)+1,output_dim=output_length, \n",
    "             input_length=55,embeddings_regularizer=keras.regularizers.l2(.001))(inputs2)\n",
    "att_in=LSTM(100,return_sequences=True,dropout=0.3)(x1)        ### see how to use recurrent_dropout=0.2\n",
    "att_out=attention()(att_in)\n",
    "x1=LSTM(100,dropout=0.3)(x1)\n",
    "outputs1=Dense(59,activation='softmax')(x1)\n",
    "model2=Model(inputs2,outputs1)\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3fc8ouoMFb4"
   },
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "# model.fit(x=x_train_re,y=y_train,batch_size=100,epochs=10,verbose=1,shuffle=True,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TTDHFcnqabS"
   },
   "source": [
    "Implementing BERT using FastAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRo1guBAWbmN"
   },
   "outputs": [],
   "source": [
    "# For this we need to install libraries like fastai and transformers\n",
    "# already colab has fastai; so installing transformers now\n",
    "\n",
    "# pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqZNYs67vWWc"
   },
   "source": [
    "Implementing BERT using keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DQh5btWGXDaN",
    "outputId": "8c522d57-4834-479a-f35f-da62f059fdc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras_bert\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.17.5)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.2.5)\n",
      "Collecting keras-transformer>=0.30.0\n",
      "  Downloading https://files.pythonhosted.org/packages/54/0c/fede535ac576c03863c44bf2e0bf051fe21f5e10103631b6b6236ae446f3/keras-transformer-0.32.0.tar.gz\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.8.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.4.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
      "Collecting keras-pos-embd>=0.10.0\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
      "Collecting keras-multi-head>=0.22.0\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
      "Collecting keras-layer-normalization>=0.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
      "Collecting keras-position-wise-feed-forward>=0.5.0\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
      "Collecting keras-embed-sim>=0.7.0\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
      "Collecting keras-self-attention==0.41.0\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
      "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
      "  Building wheel for keras-bert (setup.py): started\n",
      "  Building wheel for keras-bert (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=803a97ead1c7364942ba255a09c7e843ca46bbde71ea1df1077761ffd29262b4\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
      "  Building wheel for keras-transformer (setup.py): started\n",
      "  Building wheel for keras-transformer (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-transformer: filename=keras_transformer-0.32.0-cp36-none-any.whl size=13266 sha256=32a299c4fa1f302521a829f01ef520842136aaf4f2cd010b7a3742bd35bb64f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f0/ce/82fa5d024d5ef8e263f26a50dcee23820efe245680ce9c922a\n",
      "  Building wheel for keras-pos-embd (setup.py): started\n",
      "  Building wheel for keras-pos-embd (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=3ac4012db7a01542ac84f19a9e12ee97c3dd5f53638af744ee66a631767b3e55\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
      "  Building wheel for keras-multi-head (setup.py): started\n",
      "  Building wheel for keras-multi-head (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=a15e267f751cfb9e46216b2c96fbc09c350e99f73e3d3b87fff2ea7dc5020c10\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
      "  Building wheel for keras-layer-normalization (setup.py): started\n",
      "  Building wheel for keras-layer-normalization (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=64299da2d193b6a77904eb9b002dc401f9e0ee58f782c09e36bd813f5c09894f\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): started\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=3daa2333592dcf9d223c54893c10e77327a8358ef40c3b4cfbb92c04b39bacd6\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
      "  Building wheel for keras-embed-sim (setup.py): started\n",
      "  Building wheel for keras-embed-sim (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=29dc0dc2e3fede3163aefad19a15a0e17919aa3bd7aca8dc3069f4ba3f0b1fe4\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
      "  Building wheel for keras-self-attention (setup.py): started\n",
      "  Building wheel for keras-self-attention (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=c80e109c12b3ead46d905e9fb5c4139987458e1c152e63a47def176b8e6578dd\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
      "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
      "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
      "Successfully installed keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.32.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install keras_bert\n",
    "# from keras_bert import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "7FdkIXZiy6K-",
    "outputId": "2d11d770-50bf-49e9-9838-5d1708fb124a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/e6/55ed98ef52b168a38192da1aff7265c640f214009790220664ee3b4cb52a/bert-2.2.0.tar.gz\n",
      "Collecting erlastic\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/30/f40d99fe35c38c2e0415b1e746c89569f2483e64ef65d054b9f0f382f234/erlastic-2.0.0.tar.gz\n",
      "Building wheels for collected packages: bert, erlastic\n",
      "  Building wheel for bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert: filename=bert-2.2.0-cp36-none-any.whl size=3756 sha256=693c76c0d8188c861e26b6626f4bca12f4e18ac7ba1991f655e634ed9988c1e9\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/71/b7/941459453bd38e5d97a8c886361dee19325e9933c9cf88ad46\n",
      "  Building wheel for erlastic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for erlastic: filename=erlastic-2.0.0-cp36-none-any.whl size=6786 sha256=0f6b4097b5592c6fb08e09e1379acf086337103590d14bccf5e63b532e9253cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/02/62/46/93c713a5f061aeeb4f16eb6bf5ee798816e6ddda70faa78e69\n",
      "Successfully built bert erlastic\n",
      "Installing collected packages: erlastic, bert\n",
      "Successfully installed bert-2.2.0 erlastic-2.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6CVhbHm3vU23"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZIxg9CBpvUzl"
   },
   "outputs": [],
   "source": [
    "# param path for bert model\n",
    "# ref: https://github.com/strongio/keras-bert/blob/master/keras-bert.ipynb\n",
    "\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7iT39kd8qYEA"
   },
   "outputs": [],
   "source": [
    "class BertLayer(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "maqkH1-qqYA3"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length): \n",
    "    in_id = keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = keras.layers.Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = keras.layers.Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    dense = keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    pred = keras.layers.Dense(59, activation='softmax')(dense)\n",
    "    \n",
    "    model = keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zkbAZKg8HXz"
   },
   "outputs": [],
   "source": [
    "# max_seq_length = max_len\n",
    "max_seq_length = 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 952
    },
    "colab_type": "code",
    "id": "Q-TuKeOOqX-G",
    "outputId": "7603d5ac-c780-4bfe-daec-250a6a98507d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 55)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 55)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 55)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        ((None, 55), 768)    110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 ((None, 55), 256)    196864      bert_layer_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 ((None, 55), 59)     15163       dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,316,917\n",
      "Trainable params: 22,066,235\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "Train on 3388 samples, validate on 847 samples\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3388/3388 [==============================] - 1134s 335ms/step - loss: 0.0609 - acc: 0.9827 - val_loss: 0.0571 - val_acc: 0.9831\n",
      "Epoch 2/2\n",
      "3388/3388 [==============================] - 1125s 332ms/step - loss: 0.0592 - acc: 0.9827 - val_loss: 0.0610 - val_acc: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6402c40588>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(max_seq_length)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model.fit(\n",
    "    [x_train_re, x_train_re, x_train_re], \n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=2,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "# model.fit(x_train_re, y_train, epochs = 10, batch_size=batch_size, verbose = 2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NnGOVq-NqX0l"
   },
   "outputs": [],
   "source": [
    "# model.save('BertModel.h5')\n",
    "# pre_save_preds = model.predict([test_input_ids[0:100], \n",
    "#                                 test_input_masks[0:100], \n",
    "#                                 test_segment_ids[0:100]]\n",
    "#                               ) # predictions before we clear and reload model\n",
    "\n",
    "# # Clear and load model\n",
    "# model = None\n",
    "# model = build_model(max_seq_length)\n",
    "# initialize_vars(sess)\n",
    "# model.load_weights('BertModel.h5')\n",
    "\n",
    "# post_save_preds = model.predict([test_input_ids[0:100], \n",
    "#                                 test_input_masks[0:100], \n",
    "#                                 test_segment_ids[0:100]]\n",
    "#                               ) # predictions after we clear and reload model\n",
    "# all(pre_save_preds == post_save_preds) # Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hz1V8aphqXx1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bidir_LSTM_ELMO_Attention_Models.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
